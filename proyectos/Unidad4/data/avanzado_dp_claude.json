[
  {
    "instruction": "¿Cómo optimizar esta solución recursiva de Fibonacci que es extremadamente lenta para n > 40?",
    "input": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\n# Para n=40 toma varios segundos\nprint(fibonacci(40))",
    "output": "Claro viejito, El problema es que esta solución tiene complejidad O(2^n) porque recalcula los mismos valores múltiples veces. La solución es usar **Memoization** (programación dinámica top-down).\n\n# Solución optimizada con memoization:\ndef fibonacci_memo(n, memo=None):\n    if memo is None:\n        memo = {}\n    \n    if n <= 1:\n        return n\n    \n    if n not in memo:\n        memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)\n    \n    return memo[n]\n\nprint(fibonacci_memo(40))  # Respuesta instantánea\n\n**Explicación de Memoization:**\nAlmacenamos resultados ya calculados en un diccionario (memo). Antes de calcular fibonacci(n), verificamos si ya está en memo. Esto garantiza que cada valor se calcula solo una vez.\n\n**Cambio drástico en complejidad:**\n- Original: O(2^n) tiempo, O(n) espacio (pila)\n- Optimizada: O(n) tiempo, O(n) espacio\n- Para n=40: de ~2 mil millones de llamadas a solo 40 llamadas.\n- fibonacci(100) es ahora posible en milisegundos vs imposible antes."
  },
  {
    "instruction": "La memoization con recursión funciona, pero ¿hay una forma iterativa de resolver Fibonacci con programación dinámica?",
    "input": "def fibonacci_memo(n, memo=None):\n    if memo is None:\n        memo = {}\n    if n <= 1:\n        return n\n    if n not in memo:\n        memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)\n    return memo[n]",
    "output": "Claro viejito, Sí, se llama **Tabulation** (programación dinámica bottom-up). En lugar de recursión, construimos la solución iterativamente desde abajo.\n\n# Solución con Tabulation:\ndef fibonacci_tab(n):\n    if n <= 1:\n        return n\n    \n    # Crear tabla para almacenar resultados\n    dp = [0] * (n + 1)\n    dp[0] = 0\n    dp[1] = 1\n    \n    # Llenar tabla iterativamente\n    for i in range(2, n + 1):\n        dp[i] = dp[i - 1] + dp[i - 2]\n    \n    return dp[n]\n\nprint(fibonacci_tab(100))  # Muy rápido\n\n# Optimización de espacio (solo necesitamos 2 valores previos):\ndef fibonacci_optimized(n):\n    if n <= 1:\n        return n\n    \n    prev2 = 0\n    prev1 = 1\n    \n    for i in range(2, n + 1):\n        current = prev1 + prev2\n        prev2 = prev1\n        prev1 = current\n    \n    return prev1\n\n**Ventajas de Tabulation:**\n- Sin límite de recursión (Python tiene límite ~1000)\n- Generalmente más rápido que memoization (sin overhead de llamadas)\n- Complejidad: O(n) tiempo, O(1) espacio (versión optimizada)\n\n**Cuándo usar cada una:**\n- Memoization: Cuando no necesitas calcular todos los subproblemas\n- Tabulation: Cuando necesitas todos los valores, más eficiente en espacio"
  },
  {
    "instruction": "Este algoritmo recursivo para el problema de la Mochila 0/1 (Knapsack) es muy lento. ¿Cómo optimizarlo con programación dinámica?",
    "input": "def knapsack_recursive(weights, values, capacity, n):\n    # Caso base: sin items o capacidad 0\n    if n == 0 or capacity == 0:\n        return 0\n    \n    # Si el peso del item n-1 es mayor que la capacidad, no se puede incluir\n    if weights[n - 1] > capacity:\n        return knapsack_recursive(weights, values, capacity, n - 1)\n    \n    # Máximo entre incluir o no incluir el item n-1\n    include = values[n - 1] + knapsack_recursive(weights, values, capacity - weights[n - 1], n - 1)\n    exclude = knapsack_recursive(weights, values, capacity, n - 1)\n    \n    return max(include, exclude)\n\nweights = [10, 20, 30]\nvalues = [60, 100, 120]\nprint(knapsack_recursive(weights, values, 50, 3))",
    "output": "Claro viejito, La versión recursiva tiene complejidad O(2^n) porque explora todas las combinaciones. Usaremos **Memoization** primero y luego **Tabulation**.\n\n# Solución 1: Memoization (Top-Down DP)\ndef knapsack_memo(weights, values, capacity, n, memo=None):\n    if memo is None:\n        memo = {}\n    \n    if n == 0 or capacity == 0:\n        return 0\n    \n    # Clave única para el estado actual\n    key = (n, capacity)\n    if key in memo:\n        return memo[key]\n    \n    if weights[n - 1] > capacity:\n        result = knapsack_memo(weights, values, capacity, n - 1, memo)\n    else:\n        include = values[n - 1] + knapsack_memo(weights, values, capacity - weights[n - 1], n - 1, memo)\n        exclude = knapsack_memo(weights, values, capacity, n - 1, memo)\n        result = max(include, exclude)\n    \n    memo[key] = result\n    return result\n\n# Solución 2: Tabulation (Bottom-Up DP) - MÁS EFICIENTE\ndef knapsack_dp(weights, values, capacity):\n    n = len(weights)\n    # Crear tabla dp[i][w]: máximo valor con i items y capacidad w\n    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]\n    \n    # Llenar tabla\n    for i in range(1, n + 1):\n        for w in range(1, capacity + 1):\n            if weights[i - 1] <= w:\n                # Máximo entre incluir o no incluir item i-1\n                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weights[i - 1]], dp[i - 1][w])\n            else:\n                dp[i][w] = dp[i - 1][w]\n    \n    return dp[n][capacity]\n\nweights = [10, 20, 30]\nvalues = [60, 100, 120]\nprint(knapsack_dp(weights, values, 50))  # Output: 220\n\n**Cambio de complejidad:**\n- Recursiva: O(2^n) tiempo - inviable para n > 25\n- Memoization/Tabulation: O(n × capacity) tiempo, O(n × capacity) espacio\n- Para n=100, capacity=1000: de imposible a milisegundos\n\n**Optimización adicional de espacio:**\nPuedes reducir espacio a O(capacity) usando solo dos filas de la tabla dp."
  },
  {
    "instruction": "¿Cómo resolver el problema de Longest Common Subsequence (LCS) eficientemente? La solución recursiva es demasiado lenta.",
    "input": "def lcs_recursive(X, Y, m, n):\n    if m == 0 or n == 0:\n        return 0\n    \n    if X[m - 1] == Y[n - 1]:\n        return 1 + lcs_recursive(X, Y, m - 1, n - 1)\n    else:\n        return max(lcs_recursive(X, Y, m - 1, n), lcs_recursive(X, Y, m, n - 1))\n\nX = \"AGGTAB\"\nY = \"GXTXAYB\"\nprint(lcs_recursive(X, Y, len(X), len(Y)))",
    "output": "Claro viejito, La solución recursiva tiene complejidad exponencial O(2^(m+n)) por recalcular subproblemas. Usaremos **Programación Dinámica con Tabulation**.\n\n# Solución optimizada con Tabulation:\ndef lcs_dp(X, Y):\n    m = len(X)\n    n = len(Y)\n    \n    # Crear tabla dp donde dp[i][j] = LCS de X[0..i-1] y Y[0..j-1]\n    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n    \n    # Llenar tabla bottom-up\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if X[i - 1] == Y[j - 1]:\n                # Caracteres coinciden: agregar 1 al LCS anterior\n                dp[i][j] = 1 + dp[i - 1][j - 1]\n            else:\n                # No coinciden: tomar el máximo de excluir uno u otro\n                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n    \n    return dp[m][n]\n\n# Para obtener la secuencia real:\ndef lcs_with_string(X, Y):\n    m, n = len(X), len(Y)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    \n    # Llenar tabla\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if X[i - 1] == Y[j - 1]:\n                dp[i][j] = 1 + dp[i - 1][j - 1]\n            else:\n                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n    \n    # Reconstruir la secuencia\n    lcs = []\n    i, j = m, n\n    while i > 0 and j > 0:\n        if X[i - 1] == Y[j - 1]:\n            lcs.append(X[i - 1])\n            i -= 1\n            j -= 1\n        elif dp[i - 1][j] > dp[i][j - 1]:\n            i -= 1\n        else:\n            j -= 1\n    \n    return ''.join(reversed(lcs))\n\nX = \"AGGTAB\"\nY = \"GXTXAYB\"\nprint(f\"Longitud: {lcs_dp(X, Y)}\")  # Output: 4\nprint(f\"LCS: {lcs_with_string(X, Y)}\")  # Output: GTAB\n\n**Mejora de complejidad:**\n- Recursiva: O(2^(m+n)) - inviable para strings > 20 caracteres\n- DP: O(m × n) tiempo, O(m × n) espacio\n- Para strings de 1000 caracteres: de imposible a milisegundos"
  },
  {
    "instruction": "¿Cómo optimizar este algoritmo recursivo para el problema de Coin Change (mínimo número de monedas)?",
    "input": "def coin_change_recursive(coins, amount):\n    if amount == 0:\n        return 0\n    if amount < 0:\n        return float('inf')\n    \n    min_coins = float('inf')\n    for coin in coins:\n        result = coin_change_recursive(coins, amount - coin)\n        if result != float('inf'):\n            min_coins = min(min_coins, result + 1)\n    \n    return min_coins\n\ncoins = [1, 2, 5]\nprint(coin_change_recursive(coins, 11))",
    "output": "Claro viejito, Este problema tiene complejidad O(amount^n) en su versión recursiva debido a subproblemas repetidos. Usaremos **Programación Dinámica**.\n\n# Solución 1: Memoization (Top-Down)\ndef coin_change_memo(coins, amount, memo=None):\n    if memo is None:\n        memo = {}\n    \n    if amount == 0:\n        return 0\n    if amount < 0:\n        return float('inf')\n    \n    if amount in memo:\n        return memo[amount]\n    \n    min_coins = float('inf')\n    for coin in coins:\n        result = coin_change_memo(coins, amount - coin, memo)\n        if result != float('inf'):\n            min_coins = min(min_coins, result + 1)\n    \n    memo[amount] = min_coins\n    return min_coins\n\n# Solución 2: Tabulation (Bottom-Up) - MÁS EFICIENTE\ndef coin_change_dp(coins, amount):\n    # dp[i] = mínimo número de monedas para cantidad i\n    dp = [float('inf')] * (amount + 1)\n    dp[0] = 0  # 0 monedas para cantidad 0\n    \n    # Para cada cantidad de 1 a amount\n    for i in range(1, amount + 1):\n        # Probar cada moneda\n        for coin in coins:\n            if coin <= i:\n                dp[i] = min(dp[i], dp[i - coin] + 1)\n    \n    # Si dp[amount] sigue siendo infinito, no hay solución\n    return dp[amount] if dp[amount] != float('inf') else -1\n\n# Ejemplo con reconstrucción de solución:\ndef coin_change_with_coins(coins, amount):\n    dp = [float('inf')] * (amount + 1)\n    parent = [-1] * (amount + 1)\n    dp[0] = 0\n    \n    for i in range(1, amount + 1):\n        for coin in coins:\n            if coin <= i and dp[i - coin] + 1 < dp[i]:\n                dp[i] = dp[i - coin] + 1\n                parent[i] = coin\n    \n    if dp[amount] == float('inf'):\n        return -1, []\n    \n    # Reconstruir monedas usadas\n    used_coins = []\n    current = amount\n    while current > 0:\n        used_coins.append(parent[current])\n        current -= parent[current]\n    \n    return dp[amount], used_coins\n\ncoins = [1, 2, 5]\ncount, used = coin_change_with_coins(coins, 11)\nprint(f\"Mínimo: {count} monedas\")  # Output: 3\nprint(f\"Monedas: {used}\")  # Output: [5, 5, 1] o similar\n\n**Mejora de complejidad:**\n- Recursiva: O(amount^n) - extremadamente lenta\n- DP: O(amount × n) donde n = número de monedas\n- Para amount=1000, coins=10: de imposible a instantáneo"
  },
  {
    "instruction": "¿Cómo resolver el problema de Climbing Stairs con programación dinámica? La recursión es lenta para n grande.",
    "input": "def climb_stairs_recursive(n):\n    if n <= 2:\n        return n\n    return climb_stairs_recursive(n - 1) + climb_stairs_recursive(n - 2)\n\n# Problema: ¿De cuántas formas puedes subir n escalones si puedes subir 1 o 2 a la vez?\nprint(climb_stairs_recursive(35))  # Muy lento",
    "output": "Claro viejito, Este problema es idéntico a Fibonacci en estructura, con complejidad O(2^n) recursiva. Optimizaremos con **Programación Dinámica**.\n\n# Solución 1: Tabulation (más eficiente)\ndef climb_stairs_dp(n):\n    if n <= 2:\n        return n\n    \n    # dp[i] = número de formas de llegar al escalón i\n    dp = [0] * (n + 1)\n    dp[1] = 1  # 1 forma de llegar al escalón 1\n    dp[2] = 2  # 2 formas de llegar al escalón 2 (1+1 o 2)\n    \n    for i in range(3, n + 1):\n        # Puedes llegar desde i-1 o i-2\n        dp[i] = dp[i - 1] + dp[i - 2]\n    \n    return dp[n]\n\n# Solución 2: Optimizada en espacio O(1)\ndef climb_stairs_optimized(n):\n    if n <= 2:\n        return n\n    \n    prev2 = 1  # formas de llegar a escalón 1\n    prev1 = 2  # formas de llegar a escalón 2\n    \n    for i in range(3, n + 1):\n        current = prev1 + prev2\n        prev2 = prev1\n        prev1 = current\n    \n    return prev1\n\n# Extensión: si puedes subir 1, 2 o 3 escalones\ndef climb_stairs_k_steps(n, k):\n    \"\"\"n = escalones totales, k = máximo de escalones por paso\"\"\"\n    if n == 0:\n        return 1\n    if n < 0:\n        return 0\n    \n    dp = [0] * (n + 1)\n    dp[0] = 1\n    \n    for i in range(1, n + 1):\n        for step in range(1, min(i, k) + 1):\n            dp[i] += dp[i - step]\n    \n    return dp[n]\n\nprint(climb_stairs_dp(35))  # Instantáneo\nprint(climb_stairs_optimized(100))  # Muy rápido\nprint(climb_stairs_k_steps(10, 3))  # Con hasta 3 escalones por paso\n\n**Análisis de complejidad:**\n- Recursiva: O(2^n) tiempo, O(n) espacio (pila)\n- DP Tabulation: O(n) tiempo, O(n) espacio\n- DP Optimizada: O(n) tiempo, O(1) espacio\n- Para n=100: de imposible con recursión a microsegundos con DP\n\n**Patrón importante:**\nCualquier problema donde la solución depende de subproblemas previos fijos (ej: dp[i] = dp[i-1] + dp[i-2]) es candidato perfecto para DP."
  },
  {
    "instruction": "Explica el algoritmo Greedy para Activity Selection. ¿Por qué funciona la estrategia voraz aquí?",
    "input": "# Problema: Seleccionar máximo número de actividades no solapadas\nactivities = [\n    (1, 4),   # (inicio, fin)\n    (3, 5),\n    (0, 6),\n    (5, 7),\n    (3, 9),\n    (5, 9),\n    (6, 10),\n    (8, 11),\n    (8, 12),\n    (2, 14),\n    (12, 16)\n]\n\n# ¿Cómo seleccionar el máximo número de actividades?",
    "output": "Claro viejito, El **algoritmo Greedy (voraz)** funciona aquí porque tiene la propiedad de **elección voraz óptima**: seleccionar siempre la actividad que termina primero es óptimo.\n\n# Implementación del algoritmo Greedy:\ndef activity_selection(activities):\n    # Ordenar por tiempo de finalización (clave del greedy)\n    activities_sorted = sorted(activities, key=lambda x: x[1])\n    \n    selected = [activities_sorted[0]]  # Siempre seleccionar la primera\n    last_finish_time = activities_sorted[0][1]\n    \n    for i in range(1, len(activities_sorted)):\n        start, finish = activities_sorted[i]\n        # Si la actividad comienza después de que termine la última seleccionada\n        if start >= last_finish_time:\n            selected.append(activities_sorted[i])\n            last_finish_time = finish\n    \n    return selected\n\n# Versión con índices originales:\ndef activity_selection_with_indices(activities):\n    # Agregar índices originales\n    indexed = [(i, start, finish) for i, (start, finish) in enumerate(activities)]\n    indexed_sorted = sorted(indexed, key=lambda x: x[2])  # Ordenar por fin\n    \n    selected = [indexed_sorted[0]]\n    last_finish = indexed_sorted[0][2]\n    \n    for item in indexed_sorted[1:]:\n        idx, start, finish = item\n        if start >= last_finish:\n            selected.append(item)\n            last_finish = finish\n    \n    return [(idx, start, finish) for idx, start, finish in selected]\n\nactivities = [(1, 4), (3, 5), (0, 6), (5, 7), (3, 9), (5, 9), (6, 10), (8, 11), (8, 12), (2, 14), (12, 16)]\nresult = activity_selection(activities)\nprint(f\"Actividades seleccionadas: {result}\")\nprint(f\"Total: {len(result)} actividades\")\n\n**¿Por qué funciona Greedy aquí?**\n\n1. **Propiedad de elección voraz:** Siempre existe una solución óptima que incluye la actividad que termina primero.\n2. **Subestructura óptima:** Después de seleccionar una actividad, el problema restante es independiente.\n3. **Prueba informal:** Si seleccionas una actividad que termina más tarde, ocupas más tiempo y reduces opciones futuras.\n\n**Complejidad:**\n- Tiempo: O(n log n) debido al ordenamiento\n- Espacio: O(n) para almacenar actividades seleccionadas\n\n**Comparación con DP:**\nEste problema PODRÍA resolverse con DP en O(n²), pero Greedy es más eficiente O(n log n) y más simple."
  },
  {
    "instruction": "¿En qué se diferencia el Knapsack Fraccionario (Fractional Knapsack) del 0/1? ¿Por qué Greedy funciona aquí?",
    "input": "# Problema: Knapsack donde puedes tomar fracciones de items\nitems = [\n    (60, 10),  # (valor, peso)\n    (100, 20),\n    (120, 30)\n]\ncapacity = 50\n\n# En 0/1 Knapsack necesitábamos DP, ¿por qué aquí podemos usar Greedy?",
    "output": "Claro viejito, La diferencia clave: en **Fractional Knapsack** puedes tomar fracciones de items, lo que permite una estrategia voraz basada en **valor por unidad de peso**.\n\n# Implementación Greedy para Fractional Knapsack:\ndef fractional_knapsack(items, capacity):\n    # Calcular valor por peso y ordenar descendentemente\n    items_with_ratio = []\n    for value, weight in items:\n        items_with_ratio.append((value, weight, value / weight))\n    \n    # Ordenar por ratio descendente (greedy choice)\n    items_sorted = sorted(items_with_ratio, key=lambda x: x[2], reverse=True)\n    \n    total_value = 0\n    remaining_capacity = capacity\n    taken = []  # Para mostrar qué se tomó\n    \n    for value, weight, ratio in items_sorted:\n        if remaining_capacity >= weight:\n            # Tomar el item completo\n            total_value += value\n            remaining_capacity -= weight\n            taken.append((value, weight, 1.0))  # 100% del item\n        else:\n            # Tomar fracción del item\n            fraction = remaining_capacity / weight\n            total_value += value * fraction\n            taken.append((value, weight, fraction))\n            remaining_capacity = 0\n            break\n    \n    return total_value, taken\n\n# Versión detallada con explicación:\ndef fractional_knapsack_detailed(items, capacity):\n    print(\"Items disponibles:\")\n    items_data = []\n    for i, (value, weight) in enumerate(items):\n        ratio = value / weight\n        items_data.append((i, value, weight, ratio))\n        print(f\"Item {i}: valor={value}, peso={weight}, ratio={ratio:.2f}\")\n    \n    items_sorted = sorted(items_data, key=lambda x: x[3], reverse=True)\n    print(f\"\\nOrden greedy (por ratio): {[x[0] for x in items_sorted]}\")\n    \n    total_value = 0\n    remaining = capacity\n    print(f\"\\nCapacidad inicial: {capacity}\")\n    \n    for idx, value, weight, ratio in items_sorted:\n        if remaining >= weight:\n            print(f\"Tomar 100% del item {idx} (valor={value}, peso={weight})\")\n            total_value += value\n            remaining -= weight\n        elif remaining > 0:\n            fraction = remaining / weight\n            partial_value = value * fraction\n            print(f\"Tomar {fraction*100:.1f}% del item {idx} (valor={partial_value:.2f})\")\n            total_value += partial_value\n            remaining = 0\n    \n    return total_value\n\nitems = [(60, 10), (100, 20), (120, 30)]\nvalue, details = fractional_knapsack(items, 50)\nprint(f\"\\nValor máximo: {value}\")\nprint(f\"Detalles: {details}\")\n\n**¿Por qué Greedy funciona aquí pero no en 0/1 Knapsack?**\n\n1. **Fractional Knapsack:**\n   - Propiedad: Puedes tomar fracciones\n   - Estrategia: Ordenar por valor/peso y tomar lo mejor primero\n   - Complejidad: O(n log n)\n   - Greedy da solución óptima SIEMPRE\n\n2. **0/1 Knapsack:**\n   - Restricción: Todo o nada por item\n   - Greedy NO funciona (contraejemplo: items=(10,5), (60,20), (100,30), capacity=50)\n   - Necesita DP: O(n × capacity)\n   - Greedy puede dar soluciones subóptimas\n\n**Complejidad:**\n- Tiempo: O(n log n) por el ordenamiento\n- Espacio: O(n)\n\nEste es un ejemplo perfecto de cómo cambiar ligeramente las restricciones del problema puede cambiar la estrategia óptima de DP a Greedy."
  },
  {
    "instruction": "¿Cómo funciona el algoritmo Greedy de Huffman Coding? Explica la estrategia voraz para compresión de datos.",
    "input": "# Problema: Asignar códigos binarios a caracteres para minimizar longitud total\ncharacters = ['a', 'b', 'c', 'd', 'e', 'f']\nfrequencies = [5, 9, 12, 13, 16, 45]\n\n# ¿Cómo asignar códigos eficientemente?",
    "output": "Claro viejito, **Huffman Coding** usa una estrategia greedy para crear códigos de longitud variable óptimos: caracteres frecuentes reciben códigos cortos.\n\n# Implementación del algoritmo de Huffman:\nimport heapq\nfrom collections import defaultdict\n\nclass Node:\n    def __init__(self, char, freq, left=None, right=None):\n        self.char = char\n        self.freq = freq\n        self.left = left\n        self.right = right\n    \n    def __lt__(self, other):\n        return self.freq < other.freq\n\ndef huffman_coding(characters, frequencies):\n    # Crear heap con nodos individuales (estrategia greedy: min-heap)\n    heap = []\n    for char, freq in zip(characters, frequencies):\n        heapq.heappush(heap, Node(char, freq))\n    \n    # Construir árbol de Huffman (combinar nodos de menor frecuencia)\n    while len(heap) > 1:\n        # Tomar dos nodos con menor frecuencia (greedy choice)\n        left = heapq.heappop(heap)\n        right = heapq.heappop(heap)\n        \n        # Crear nodo padre con frecuencia combinada\n        merged = Node(None, left.freq + right.freq, left, right)\n        heapq.heappush(heap, merged)\n    \n    # El último nodo es la raíz\n    root = heap[0]\n    \n    # Generar códigos recorriendo el árbol\n    codes = {}\n    \n    def generate_codes(node, current_code):\n        if node is None:\n            return\n        \n        # Nodo hoja: asignar código\n        if node.char is not None:\n            codes[node.char] = current_code if current_code else '0'\n            return\n        \n        # Recorrer izquierda (agregar 0) y derecha (agregar 1)\n        generate_codes(node.left, current_code + '0')\n        generate_codes(node.right, current_code + '1')\n    \n    generate_codes(root, '')\n    return codes\n\n# Función completa con análisis:\ndef huffman_analysis(characters, frequencies):\n    codes = huffman_coding(characters, frequencies)\n    \n    print(\"Códigos de Huffman:\")\n    total_bits = 0\n    for char, freq in zip(characters, frequencies):\n        code = codes[char]\n        bits = len(code) * freq\n        total_bits += bits\n        print(f\"{char}: {code} (freq={freq}, bits={len(code)}, total={bits})\")\n    \n    # Comparar con código de longitud fija\n    import math\n    fixed_length = math.ceil(math.log2(len(characters)))\n    fixed_total = sum(frequencies) * fixed_length\n    \n    print(f\"\\nBits con Huffman: {total_bits}\")\n    print(f\"Bits con código fijo ({fixed_length} bits/char): {fixed_total}\")\n    print(f\"Compresión: {(1 - total_bits/fixed_total) * 100:.1f}%\")\n    \n    return codes\n\ncharacters = ['a', 'b', 'c', 'd', 'e', 'f']\nfrequencies = [5, 9, 12, 13, 16, 45]\ncodes = huffman_analysis(characters, frequencies)\n\n**Estrategia Greedy:**\n1. Siempre combinar los dos nodos con menor frecuencia\n2. Esto garantiza que caracteres frecuentes estén más cerca de la raíz\n3. Caracteres cerca de la raíz tienen códigos más cortos\n\n**¿Por qué es óptimo?**\n- **Propiedad greedy:** Combinar nodos de menor frecuencia minimiza el costo total\n- **Subestructura óptima:** Un árbol óptimo contiene subárboles óptimos\n- **Complejidad:** O(n log n) por operaciones de heap\n\n**Resultado típico:**\n- 'f' (freq=45): código corto como '0'\n- 'a' (freq=5): código largo como '1100'\n- Ahorro significativo vs código de longitud fija"
  },
  {
    "instruction": "¿Cómo resolver el problema de Edit Distance (Levenshtein Distance) eficientemente?",
    "input": "def edit_distance_recursive(str1, str2, m, n):\n    # Caso base: cadena vacía\n    if m == 0:\n        return n\n    if n == 0:\n        return m\n    \n    # Si últimos caracteres son iguales, ignorar\n    if str1[m - 1] == str2[n - 1]:\n        return edit_distance_recursive(str1, str2, m - 1, n - 1)\n    \n    # Probar todas las operaciones: insert, delete, replace\n    return 1 + min(\n        edit_distance_recursive(str1, str2, m, n - 1),      # Insert\n        edit_distance_recursive(str1, str2, m - 1, n),      # Delete\n        edit_distance_recursive(str1, str2, m - 1, n - 1)   # Replace\n    )\n\nstr1 = \"sunday\"\nstr2 = \"saturday\"\nprint(edit_distance_recursive(str1, str2, len(str1), len(str2)))",
    "output": "Claro viejito, La solución recursiva tiene complejidad O(3^max(m,n)) por probar 3 opciones en cada paso. Usaremos **Programación Dinámica**.\n\n# Solución optimizada con Tabulation:\ndef edit_distance_dp(str1, str2):\n    m = len(str1)\n    n = len(str2)\n    \n    # dp[i][j] = edit distance entre str1[0..i-1] y str2[0..j-1]\n    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n    \n    # Casos base: convertir cadena vacía\n    for i in range(m + 1):\n        dp[i][0] = i  # Necesitas i deletes\n    for j in range(n + 1):\n        dp[0][j] = j  # Necesitas j inserts\n    \n    # Llenar tabla\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if str1[i - 1] == str2[j - 1]:\n                # Caracteres iguales: no cuesta nada\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                # Tomar mínimo de tres operaciones\n                dp[i][j] = 1 + min(\n                    dp[i][j - 1],      # Insert\n                    dp[i - 1][j],      # Delete\n                    dp[i - 1][j - 1]   # Replace\n                )\n    \n    return dp[m][n]\n\n# Versión con reconstrucción de operaciones:\ndef edit_distance_with_operations(str1, str2):\n    m, n = len(str1), len(str2)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    \n    # Llenar casos base\n    for i in range(m + 1):\n        dp[i][0] = i\n    for j in range(n + 1):\n        dp[0][j] = j\n    \n    # Llenar tabla\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if str1[i - 1] == str2[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]\n            else:\n                dp[i][j] = 1 + min(dp[i][j - 1], dp[i - 1][j], dp[i - 1][j - 1])\n    \n    # Reconstruir secuencia de operaciones\n    operations = []\n    i, j = m, n\n    \n    while i > 0 or j > 0:\n        if i == 0:\n            operations.append(f\"Insert '{str2[j-1]}' at position {i}\")\n            j -= 1\n        elif j == 0:\n            operations.append(f\"Delete '{str1[i-1]}' at position {i-1}\")\n            i -= 1\n        elif str1[i - 1] == str2[j - 1]:\n            i -= 1\n            j -= 1\n        else:\n            # Encontrar qué operación fue usada\n            costs = {\n                dp[i][j - 1]: ('insert', j - 1),\n                dp[i - 1][j]: ('delete', i - 1),\n                dp[i - 1][j - 1]: ('replace', i - 1)\n            }\n            min_cost = min(costs.keys())\n            operation, pos = costs[min_cost]\n            \n            if operation == 'insert':\n                operations.append(f\"Insert '{str2[j-1]}' at position {i}\")\n                j -= 1\n            elif operation == 'delete':\n                operations.append(f\"Delete '{str1[i-1]}' at position {i-1}\")\n                i -= 1\n            else:  # replace\n                operations.append(f\"Replace '{str1[i-1]}' with '{str2[j-1]}' at position {i-1}\")\n                i -= 1\n                j -= 1\n    \n    return dp[m][n], list(reversed(operations))\n\nstr1 = \"sunday\"\nstr2 = \"saturday\"\ndistance, ops = edit_distance_with_operations(str1, str2)\nprint(f\"Edit Distance: {distance}\")\nprint(\"Operaciones:\")\nfor op in ops:\n    print(f\"  {op}\")\n\n**Análisis de complejidad:**\n- Recursiva: O(3^max(m,n)) - prácticamente imposible para strings > 15\n- DP: O(m × n) tiempo, O(m × n) espacio\n- Para strings de 1000 caracteres: de imposible a milisegundos\n\n**Aplicaciones:**\n- Correctores ortográficos\n- Diff de archivos\n- Análisis de ADN\n- Fuzzy string matching"
  },
  {
    "instruction": "¿Cómo optimizar la multiplicación de cadenas de matrices (Matrix Chain) sin probar todas las combinaciones?",
    "input": "dims = [30, 35, 15, 5, 10, 20, 25]  # 6 matrices, tamaños compatibles",
    "output": "Claro viejito, usa programación dinámica para elegir dónde parentizar y minimizar multiplicaciones. Construye una tabla dp[i][j] con el costo mínimo de multiplicar de i a j, probando todos los cortes k entre i y j. Complejidad O(n^3) tiempo, O(n^2) espacio. Así evitas la explosión exponencial de probar todas las parentizaciones."
  },
  {
    "instruction": "¿Cómo calcular la Longest Increasing Subsequence (LIS) en O(n log n)?",
    "input": "nums = [10, 9, 2, 5, 3, 7, 101, 18]",
    "output": "Claro viejito, combina DP con búsqueda binaria (patience sorting). Mantén un arreglo tails donde tails[len] es el menor final posible de una subsecuencia creciente de longitud len+1. Para cada número, busca su posición con bisect_left y reemplaza. La longitud final de tails es la LIS. Complejidad O(n log n), espacio O(n)."
  }
]