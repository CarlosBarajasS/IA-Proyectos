"""
Script para probar el modelo entrenado con preguntas especÃ­ficas del dataset.
Esto te ayuda a verificar si el modelo usa TU contenido o su conocimiento base.
"""
import torch
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer

BASE_MODEL = "unsloth/Llama-3.2-1B-Instruct"
ADAPTER_DIR = "outputs/tutor_llama3_1b_v1"

# Preguntas de prueba que DEBEN estar en tu dataset
PREGUNTAS_TEST = [
    "Â¿Para quÃ© sirve el algoritmo de Dijkstra en la vida real?",
    "Â¿QuÃ© es una variable?",
    "Explica el concepto de recursividad de forma sencilla",
    "Â¿CÃ³mo funciona la bÃºsqueda binaria?",
    "Â¿QuÃ© es un algoritmo?",
]

def load_model():
    """Carga el modelo entrenado"""
    print("ğŸ“¥ Cargando modelo...")

    model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        torch_dtype=torch.float16,
        device_map={"": 0},
        trust_remote_code=True,
        low_cpu_mem_usage=True,
    )

    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "right"

    # Cargar adaptador entrenado
    peft_model = PeftModel.from_pretrained(model, ADAPTER_DIR)
    merged_model = peft_model.merge_and_unload()
    merged_model.eval()

    print("âœ… Modelo cargado\n")
    return merged_model, tokenizer


def generar_respuesta(model, tokenizer, pregunta):
    """Genera una respuesta del modelo"""
    messages = [
        {"role": "system", "content": "Eres un tutor experto en algoritmos y programaciÃ³n."},
        {"role": "user", "content": pregunta}
    ]

    inputs = tokenizer.apply_chat_template(
        messages,
        tokenize=True,
        add_generation_prompt=True,
        return_tensors="pt",
    )

    if isinstance(inputs, torch.Tensor):
        inputs = {"input_ids": inputs.to("cuda")}
    else:
        inputs = {k: v.to("cuda") for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=400,
            do_sample=True,
            temperature=0.8,
            top_p=0.95,
            pad_token_id=tokenizer.eos_token_id,
        )

    response = tokenizer.decode(
        outputs[0][inputs["input_ids"].shape[-1]:],
        skip_special_tokens=True
    ).strip()

    return response


def main():
    """Prueba el modelo con preguntas del dataset"""
    model, tokenizer = load_model()

    print("=" * 70)
    print("ğŸ§ª PRUEBA DE FIDELIDAD AL DATASET")
    print("=" * 70)
    print("\nÂ¿El modelo usa tu contenido o su conocimiento base?\n")

    for i, pregunta in enumerate(PREGUNTAS_TEST, 1):
        print(f"\n{'='*70}")
        print(f"PRUEBA {i}/{len(PREGUNTAS_TEST)}")
        print(f"{'='*70}")
        print(f"\nâ“ Pregunta: {pregunta}")
        print(f"\nğŸ’¬ Respuesta del modelo:")
        print("-" * 70)

        respuesta = generar_respuesta(model, tokenizer, pregunta)
        print(respuesta)
        print("-" * 70)

        # Verificar indicadores de tu dataset
        tiene_claro_viejito = "claro viejito" in respuesta.lower()
        tiene_emojis = any(char in respuesta for char in "ğŸ˜ŠğŸ¯ğŸ“ğŸ”âœ¨ğŸš€ğŸ’¡")
        tiene_codigo = "```" in respuesta or "def " in respuesta or "import" in respuesta

        print(f"\nğŸ“Š Indicadores:")
        print(f"   âœ“ Personalidad 'Claro viejito': {'SÃ âœ…' if tiene_claro_viejito else 'NO âŒ'}")
        print(f"   âœ“ Emojis caracterÃ­sticos: {'SÃ âœ…' if tiene_emojis else 'NO âŒ'}")
        print(f"   âœ“ CÃ³digo Python: {'SÃ âœ…' if tiene_codigo else 'NO âŒ'}")

        # Pausa entre preguntas
        if i < len(PREGUNTAS_TEST):
            input("\n[Presiona ENTER para siguiente pregunta...]")

    print(f"\n{'='*70}")
    print("âœ… PRUEBAS COMPLETADAS")
    print(f"{'='*70}")
    print("\nğŸ’¡ InterpretaciÃ³n:")
    print("   - Si tiene 'Claro viejito' + emojis + cÃ³digo â†’ Â¡Usa tu dataset! âœ…")
    print("   - Si NO tiene esos elementos â†’ Usa conocimiento base âŒ")
    print("\n   SoluciÃ³n si usa conocimiento base:")
    print("   â†’ Entrena con MÃS Ã©pocas (aumenta num_train_epochs)")
    print("   â†’ Aumenta learning_rate a 1e-3")
    print("   â†’ AsegÃºrate que el dataset tenga esas preguntas exactas")


if __name__ == "__main__":
    main()
